{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"mount_file_id":"13ktmZGLnrRASjieRWYOtgGoqTEYyAAMV","authorship_tag":"ABX9TyNVbGwM5v6/4Z2aqtW+9evp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#SYSC 5906:\n","## **Room Detection - Dataset Processor: PKL**\n","## Verison 2\n","---\n","Script to process a subset of the *cleaned* MIT Indoor Scenes dataset. This generates a new dataset to train a room/environment classifier, this version includes X/Y coordinates for each object and only includes a subset of the room types.\n","\n","*This script is meant to run on the modified/condensed version of the MIT\n","dataset.*\n","\n","This script **outputs the data as a .pkl file**, for use with Keras/TF."],"metadata":{"id":"Etlfo3TDDc1-"}},{"cell_type":"markdown","source":["###Step 1: Access Drive\n","Mount the drive with the provided .zip file of code located in it"],"metadata":{"id":"waYG6-MpDyRC"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8YSLhrfxDInB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661020421694,"user_tz":240,"elapsed":2493,"user":{"displayName":"Max Polzin","userId":"03709591342440376320"}},"outputId":"085acb6c-c29e-4767-fd09-21b1b78523c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}],"source":["#Enter the gdrive\n","from google.colab import drive\n","drive.mount('/gdrive',force_remount=True)"]},{"cell_type":"code","source":["#Install missing libraries\n","%%capture \n","!pip install pandas_read_xml"],"metadata":{"id":"_xEyrR6SKLCo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Step 2: Setup\n","Import relevenat libraries, load original MIT dataset into colabs (without the images) and get the folders inside"],"metadata":{"id":"pkvQ3v24D2NJ"}},{"cell_type":"code","source":["import pandas as pd\n","import xml.etree.ElementTree as et\n","import os\n","import pickle\n","from pathlib import Path\n","import glob\n","import csv\n","import numpy as np\n","from collections import Counter\n","import pandas_read_xml as pdx\n","from pandas_read_xml import flatten, fully_flatten, auto_separate_tables\n","\n","CLEANED_DATASET_DIRECTORY = '/gdrive/My Drive/Colab Notebooks/SYSC 5906/datasets/mit_indoors/CLEANED_indoorCVPR_09annotations/CleanAnnotations/'\n","PICKLE_DIRECTORY = '/gdrive/My Drive/Colab Notebooks/SYSC 5906/datasets/mit_indoors/processed/data_subset/7 classes/'"],"metadata":{"id":"jUQ31zs1I9JO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#List of desired rooms to create a subset of the MIT dataset\n","#desiredRooms = ['bathroom','bedroom','children_room','dining_room','corridor','garage','livingroom','kitchen','office','pantry','computerroom','staircase','closet']\n","desiredRooms = ['bathroom','bedroom','dining_room','corridor','livingroom','kitchen','office']\n"],"metadata":{"id":"GA0ksLUM5UxX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Empty list for room files (which are condsensed MIT folders)\n","fileList = []\n","\n","#Read XML's from dataset folder\n","with os.scandir(CLEANED_DATASET_DIRECTORY) as entries:\n","    for entry in entries:\n","        #Keep only a subset of the rooms/files in the dataset\n","        for room in desiredRooms:\n","            entryStr = str(entry.name)\n","            if entryStr.startswith(room):\n","                #Extract file plus ground truth (room types)\n","                fileList.append(tuple((entry.name,room)))\n","                #print(entry.name)"],"metadata":{"id":"3ChzBMSS8mCL","cellView":"code"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Step 3: Parse XML\n","Extract object data from .xml's in the modified MIT dataset"],"metadata":{"id":"1ZdCbe4bF4Vs"}},{"cell_type":"code","source":["#Variables to change the end scale size of the images\n","scaled_height = 50\n","scaled_width = 50\n","\n","#List for each instance of a object in the dataset\n","listOfAllObj = []\n","listOfAllFrames=[]\n","numFiles = 0\n","\n","#List of all unique instances of a object\n","uniqueObjs = set()\n","objectMap = []\n","\n","#Cycle through all collected files\n","for file in fileList:\n","    #Open relevant files\n","    if file[0].endswith(\"xml\"): \n","        numFiles += 1\n","        file_frame=np.zeros((scaled_height,scaled_width))\n","\n","        #Create a list to hold objects temporarily\n","        fileObj = []\n","\n","        #Add room label integer to instance\n","        fileObj.append(desiredRooms.index(file[1]))\n","\n","        #Open the xml\n","        curXML = open(CLEANED_DATASET_DIRECTORY+\"/\"+file[0],\"r\",\n","                        encoding=\"UTF-8\",errors='xmlcharrefreplace')\n","        fileContents = curXML.read()\n","        \n","        #Create parser to run through the xml\n","        eTreeParser = et.XMLParser()\n","        \n","        #Create a element tree from the xml\n","        etree = et.fromstring(fileContents, parser=eTreeParser)\n","\n","        #Get width and height of original image\n","        width = etree.findall(\"width\")[0].text\n","        height = etree.findall(\"height\")[0].text\n","\n","        #Run through all of the object tags inside the element tree\n","        curObjs = etree.findall(\".//object\")\n","        for obj in curObjs:\n","            #Extract X-Y coordinates for each object\n","            objStr = obj.findall(\"name\")[0].text\n","            pts = obj.findall(\"polygon\")[0].findall(\"pt\")\n","            x_min = 2000\n","            y_min = 2000\n","            x_max = 0\n","            y_max = 0\n","            for pt in pts:\n","                x_val = int(pt.findall(\"x\")[0].text)\n","                y_val = int(pt.findall(\"y\")[0].text)\n","                x_max = max(x_max,x_val)\n","                x_min = min(x_min,x_val)\n","                y_max = max(y_max,y_val)\n","                y_min = min(y_min,y_val)\n","            #Calculate centroid of current obj\n","            y_avg = (y_max - y_min)/2\n","            x_avg = (x_max - x_min)/2\n","            cleanObjStr = objStr.strip('\\n')\n","\n","            #Scale the centroids to a consistent size\n","            y_avg_scaled = round(y_avg/int(height)*scaled_height)\n","            x_avg_scaled = round(x_avg/int(width)*scaled_width)\n","\n","            # print(\"\"+str(x_avg) + \"/\" + width + \" -> \" + str(x_avg_scaled)+\"/\"+str(scaled_width))\n","            # print(\"\"+str(y_avg) + \"/\" + height+\" -> \" + str(y_avg_scaled)+\"/\"+str(scaled_height))\n","\n","            #Replace object string with integer\n","            if cleanObjStr not in uniqueObjs:\n","                objectMap.append(cleanObjStr)\n","            \n","            # while(1):\n","            #     if file_frame[y_avg_scaled][x_avg_scaled] == 0:\n","            #         file_frame[y_avg_scaled][x_avg_scaled] = objectMap.index(cleanObjStr)\n","            #         break\n","            #     else:\n","            #         x_avg_scaled = x_avg_scaled + 1\n","            #         if(x_avg_scaled > scaled_width-1):\n","            #             x_avg_scaled = x_avg_scaled -1\n","            #             y_avg_scaled = y_avg_scaled + 1\n","                    \n","            #Store object name and position (centroid)\n","            file_frame[y_avg_scaled,x_avg_scaled] = objectMap.index(cleanObjStr)\n","\n","            obj_tuple = [objectMap.index(cleanObjStr),x_avg,y_avg]\n","\n","            fileObj.append(obj_tuple)\n","            \n","            uniqueObjs.add(cleanObjStr)\n","            \n","    #Store list of all objects from the current file\n","    listOfAllFrames.append((file_frame,desiredRooms.index(file[1])))\n","    listOfAllObj.append(fileObj)\n","print(listOfAllFrames[0])"],"metadata":{"id":"0hf6u8qRF4iU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1661019829132,"user_tz":240,"elapsed":4823,"user":{"displayName":"Max Polzin","userId":"03709591342440376320"}},"outputId":"1cb009e5-a89d-4e5d-ae33-8155249fa357"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(array([[ 0., 14.,  0., ...,  0.,  0.,  0.],\n","       [17.,  0.,  0., ...,  0.,  0.,  0.],\n","       [ 0., 15., 11., ...,  0.,  0.,  0.],\n","       ...,\n","       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n","       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n","       [ 0.,  0.,  0., ...,  0.,  0.,  0.]]), 3)\n"]}]},{"cell_type":"markdown","source":["##Step 4: Pickle the data\n","Process extracted data into a Pickle to be used with Keras\n","\n","The format looks like:\\\n","[room label [obj1 tuple] [obj1 tuple] ... [objn tuple]\n","\n","Where each tuple has: Obj label, x_avg, y_avg"],"metadata":{"id":"SmU1fMm_RGOY"}},{"cell_type":"code","source":["#Pickle the data so we can access it later\n","pckl = open(PICKLE_DIRECTORY+\"listOfAllObjLoc_v2.pkl\",\"wb\")\n","pickle.dump(listOfAllFrames,pckl)\n","pckl.close()\n","\n","#Test pickle\n","# new_pckl = open(PICKLE_DIRECTORY+\"listOfAllObjLoc.pkl\",\"rb\")\n","# new_list = pickle.load(new_pckl)\n","# new_pckl.close()"],"metadata":{"id":"gpr65xU3g54t"},"execution_count":null,"outputs":[]}]}