{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dataset_processor_CSV.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPtTe9Nj4AFqC0j6EHlF7wn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#SYSC 5906:\n","## **Room Detection - Dataset Processor: CSV**\n","\n","---\n","Script to process MIT Indoor Scenes dataset. This generates a new dataset \n","to train a room/environment classifier.\n","\n","This script **outputs the data as a .csv file**, for use with Scikitlearn."],"metadata":{"id":"Etlfo3TDDc1-"}},{"cell_type":"markdown","source":["###Step 1: Access Drive\n","Mount the drive with the provided .zip file of code located in it"],"metadata":{"id":"waYG6-MpDyRC"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8YSLhrfxDInB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660516599041,"user_tz":240,"elapsed":3553,"user":{"displayName":"Max Polzin","userId":"03709591342440376320"}},"outputId":"1ff3516d-7ce9-4ef7-b9a1-172c12c61860"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}],"source":["#Enter the gdrive\n","from google.colab import drive\n","drive.mount('/gdrive',force_remount=True)"]},{"cell_type":"code","source":["#Install missing libraries\n","%%capture \n","!pip install pandas_read_xml"],"metadata":{"id":"_xEyrR6SKLCo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Step 2: Setup\n","Import relevenat libraries, load original MIT dataset into colabs (without the images) and get the folders inside"],"metadata":{"id":"pkvQ3v24D2NJ"}},{"cell_type":"code","source":["import pandas as pd\n","import xml.etree.ElementTree as et\n","import os\n","from pathlib import Path\n","import glob\n","import csv\n","import numpy as np\n","from collections import Counter\n","import pandas_read_xml as pdx\n","from pandas_read_xml import flatten, fully_flatten, auto_separate_tables\n","\n","DATASET_DIRECTORY = '/gdrive/My Drive/Colab Notebooks/SYSC 5906/datasets/mit_indoors/indoorCVPR_09annotations/Annotations/'\n","PROCESSED_FULLSET_DIRECTORY = '/gdrive/My Drive/Colab Notebooks/SYSC 5906/datasets/mit_indoors/processed/data_fullset/processedData.csv'\n","OBJ_FULLSET_DIRECTORY = '/gdrive/My Drive/Colab Notebooks/SYSC 5906/datasets/mit_indoors/processed/data_fullset/objData.csv'\n","PROCESSED_SUBSET_DIRECTORY = '/gdrive/My Drive/Colab Notebooks/SYSC 5906/datasets/mit_indoors/processed/data_subset/processedData_subset.csv'\n","OBJ_SUBSET_DIRECTORY = '/gdrive/My Drive/Colab Notebooks/SYSC 5906/datasets/mit_indoors/processed/data_subset/objData_subset.csv'"],"metadata":{"id":"jUQ31zs1I9JO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#List of desired rooms to create a subset of the MIT dataset\n","desiredRoomSubset = ['bathroom','bedroom','children_room','dining_room','corridor','garage','livingroom','kitchen','office','pantry','computerroom','staircase','closet']\n","\n","#Subset toggle\n","subsetTog = False"],"metadata":{"id":"tiJY0T-qR6Ru"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Empty list for folders\n","folderList = []\n","\n","#Read XML's from dataset folder\n","with os.scandir(DATASET_DIRECTORY) as entries:\n","    for entry in entries:\n","        #Either keep all room types in the dataset or just a subset\n","        if (entry.name in desiredRoomSubset and subsetTog == True) or subsetTog == False: \n","            folderList.append(entry.name)\n","            #print(entry.name)\n","\n","#Generate dataframe with folder names\n","folderDF = pd.DataFrame(folderList)\n","\n","print(folderList)"],"metadata":{"id":"3ChzBMSS8mCL","cellView":"code","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660517795238,"user_tz":240,"elapsed":292,"user":{"displayName":"Max Polzin","userId":"03709591342440376320"}},"outputId":"a86d7248-8ba9-4503-8211-009c04c7b4c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['tv_studio', 'inside_subway', 'movietheater', 'nursery', 'toystore', 'winecellar', 'corridor', 'meeting_room', 'poolinside', 'greenhouse', 'lobby', 'studiomusic', 'bedroom', 'dentaloffice', 'livingroom', 'gym', 'cloister', 'stairscase', 'children_room', 'classroom', 'buffet', 'kindergarden', 'computerroom', 'warehouse', 'dining_room', 'auditorium', 'bar', 'jewelleryshop', 'hairsalon', 'florist', 'pantry', 'waitingroom', 'videostore', 'mall', 'clothingstore', 'laboratorywet', 'restaurant', 'inside_bus', 'fastfood_restaurant', 'kitchen', 'deli', 'operating_room', 'hospitalroom', 'bathroom', 'trainstation', 'prisoncell', 'artstudio', 'gameroom', 'library', 'bakery', 'office', 'airport_inside', 'elevator', 'museum', 'church_inside', 'laundromat', 'concert_hall', 'shoeshop', 'grocerystore', 'bookstore', 'bowling', 'casino', 'restaurant_kitchen', 'garage', 'locker_room', 'closet', 'subway']\n"]}]},{"cell_type":"markdown","source":["##Step 3: Parse XML\n","Extract object data from .xml's in the MIT dataset"],"metadata":{"id":"1ZdCbe4bF4Vs"}},{"cell_type":"code","source":["#Document iterator\n","def iter_docs(author):\n","    author_attr = author.attrib\n","    for doc in author.iter('document'):\n","        doc_dict = author_attr.copy()\n","        doc_dict.update(doc.attrib)\n","        doc_dict['data'] = doc.text\n","        yield doc_dict\n","\n","#Add 'author' line to end of each xml\n","def iter_author(etree):\n","    for author in etree.iter('author'):\n","        for row in iter_docs(author):\n","            yield row\n","\n","#List for each instance of a object in the dataset\n","listOfAllObj = []\n","listOfAllRooms = []\n","numFiles = 0\n","\n","#List of all unique objects\n","uniqueObjs = set()\n","\n","#List of all unique room tpyes (folders)\n","roomNames = set()\n","\n","for folder in folderDF.iloc[:,0]:\n","    roomNames.add(folder) #Record all of the possible room names\n","    for file in os.listdir(DATASET_DIRECTORY+folder):\n","        #print(folder + \" ---- \" + file)\n","        if file.endswith(\"xml\"): \n","            numFiles += 1\n","            \n","            #Create a list to hold objects temporarily\n","            fileObj = []\n","\n","            listOfAllRooms.append(folder)\n","            \n","            #Open the xml\n","            curXML = open(DATASET_DIRECTORY+folder+\"/\"+file,\"r\",\n","                          encoding=\"UTF-8\",errors='xmlcharrefreplace')\n","            fileContents = curXML.read()\n","            \n","            #Create parser to run through the xml\n","            eTreeParser = et.XMLParser()\n","            \n","            #Create a element tree from the xml\n","            etree = et.fromstring(fileContents, parser=eTreeParser)\n","  \n","            #Run through all of the object tags inside the element tree\n","            curObjs = etree.findall(\".//object\")\n","            for obj in curObjs:\n","                objStr = obj.findall(\"name\")[0].text\n","                cleanObjStr = objStr.strip('\\n')\n","                fileObj.append(cleanObjStr)\n","                uniqueObjs.add(cleanObjStr)\n","                \n","        #Store list of all objects from the current file\n","        listOfAllObj.append(fileObj)  "],"metadata":{"id":"0hf6u8qRF4iU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Step 4: Generate CSV\n","Process extracted data into new CSV format\n","\n","The format looks like:\\\n","[instance obj1 obj2 obj3 ... objn room]\\\n","[1         0     0   0   ...  0  \"kitchen\"]"],"metadata":{"id":"mVLNn36wF7XY"}},{"cell_type":"code","source":["#Create a CSV for the processed dataset\n","if subsetTog == True:\n","    processedData = open(PROCESSED_SUBSET_DIRECTORY, 'w', newline='')\n","    print(\"Building subset CSV\")\n","else:\n","    processedData = open(PROCESSED_FULLSET_DIRECTORY, 'w', newline='')\n","    print(\"Building fullset CSV\")\n","csvWriter = csv.writer(processedData, delimiter=',')\n","\n","#Create a CSV for all of the unique detected objects in the dataset\n","if subsetTog == True:\n","    objectsData = open(OBJ_SUBSET_DIRECTORY, 'w', newline='')\n","else:\n","    objectsData = open(OBJ_FULLSET_DIRECTORY, 'w', newline='')\n","csvWriter2 = csv.writer(objectsData, delimiter=',')\n","\n","#Create dataframe of rooms/scenes, objects, and object counts\n","columns = ['room']\n","for obj in uniqueObjs:\n","    columns.append(obj)\n","\n","    #Record the detected objects in CSV\n","    csvWriter2.writerow([obj])\n","\n","data = np.zeros([len(uniqueObjs)+1, numFiles])\n","\n","#List to store \"ground truths\", these are the room names\n","countedListOfObjects = [[]]\n","objectCountsDF=np.empty([len(listOfAllObj)],dtype='object')\n","objectCounts=[]\n","\n","#Cycle through the list of lists that contain the objects from each xml file\n","for i in range(len(listOfAllObj)):\n","    #Count each instance of a object in a given room type\n","    count = Counter(listOfAllObj[i]).most_common()\n","    objectCounts.append(Counter(listOfAllObj[i]))\n","    countedListOfObjects.append(count)\n","\n","#Store counted objects in the dataframe\n","data = pd.DataFrame.from_records(objectCounts)\n","data[\"RoomName\"] = listOfAllRooms\n","data = data.fillna(0) #Fill NaN with zero\n","\n","#Insert the dataframe into a CSV\n","if subsetTog == True:\n","    data.to_csv(PROCESSED_SUBSET_DIRECTORY, sep=',', index=True)\n","else:\n","    data.to_csv(PROCESSED_FULLSET_DIRECTORY, sep=',', index=True)\n","            \n","#Close the CSVs\n","processedData.close()\n","objectsData.close()"],"metadata":{"id":"79tWxHHY8fzb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660517814818,"user_tz":240,"elapsed":7642,"user":{"displayName":"Max Polzin","userId":"03709591342440376320"}},"outputId":"216c9f21-8160-4d78-9512-8d73569ebed7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Building fullset CSV\n"]}]}]}